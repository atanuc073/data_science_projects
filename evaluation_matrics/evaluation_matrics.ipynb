{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atanuc73/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/home/atanuc73/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Import Statements\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "data=np.asarray(pd.read_csv('01_evaluation-metrics_data.csv',header=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.24539 , 0.81725 , 0.      ],\n",
       "       [0.21774 , 0.76462 , 0.      ],\n",
       "       [0.20161 , 0.69737 , 0.      ],\n",
       "       [0.20161 , 0.58041 , 0.      ],\n",
       "       [0.2477  , 0.49561 , 0.      ],\n",
       "       [0.32834 , 0.44883 , 0.      ],\n",
       "       [0.39516 , 0.48099 , 0.      ],\n",
       "       [0.39286 , 0.57164 , 0.      ],\n",
       "       [0.33525 , 0.62135 , 0.      ],\n",
       "       [0.33986 , 0.71199 , 0.      ],\n",
       "       [0.34447 , 0.81433 , 0.      ],\n",
       "       [0.28226 , 0.82602 , 0.      ],\n",
       "       [0.26613 , 0.75    , 0.      ],\n",
       "       [0.26613 , 0.63596 , 0.      ],\n",
       "       [0.32604 , 0.54825 , 0.      ],\n",
       "       [0.28917 , 0.65643 , 0.      ],\n",
       "       [0.80069 , 0.71491 , 0.      ],\n",
       "       [0.80069 , 0.64181 , 0.      ],\n",
       "       [0.80069 , 0.50146 , 0.      ],\n",
       "       [0.79839 , 0.36988 , 0.      ],\n",
       "       [0.73157 , 0.25    , 0.      ],\n",
       "       [0.63249 , 0.18275 , 0.      ],\n",
       "       [0.60023 , 0.27047 , 0.      ],\n",
       "       [0.66014 , 0.34649 , 0.      ],\n",
       "       [0.70161 , 0.42251 , 0.      ],\n",
       "       [0.70853 , 0.53947 , 0.      ],\n",
       "       [0.71544 , 0.63304 , 0.      ],\n",
       "       [0.74309 , 0.72076 , 0.      ],\n",
       "       [0.75    , 0.63596 , 0.      ],\n",
       "       [0.75    , 0.46345 , 0.      ],\n",
       "       [0.72235 , 0.35526 , 0.      ],\n",
       "       [0.66935 , 0.28509 , 0.      ],\n",
       "       [0.20622 , 0.94298 , 1.      ],\n",
       "       [0.26613 , 0.8962  , 1.      ],\n",
       "       [0.38134 , 0.8962  , 1.      ],\n",
       "       [0.42051 , 0.94591 , 1.      ],\n",
       "       [0.49885 , 0.86404 , 1.      ],\n",
       "       [0.31452 , 0.93421 , 1.      ],\n",
       "       [0.53111 , 0.72076 , 1.      ],\n",
       "       [0.45276 , 0.74415 , 1.      ],\n",
       "       [0.53571 , 0.6038  , 1.      ],\n",
       "       [0.60484 , 0.71491 , 1.      ],\n",
       "       [0.60945 , 0.58333 , 1.      ],\n",
       "       [0.51267 , 0.47807 , 1.      ],\n",
       "       [0.50806 , 0.59211 , 1.      ],\n",
       "       [0.46198 , 0.30556 , 1.      ],\n",
       "       [0.5288  , 0.41082 , 1.      ],\n",
       "       [0.38594 , 0.35819 , 1.      ],\n",
       "       [0.31682 , 0.31433 , 1.      ],\n",
       "       [0.29608 , 0.20906 , 1.      ],\n",
       "       [0.36982 , 0.27632 , 1.      ],\n",
       "       [0.42972 , 0.18275 , 1.      ],\n",
       "       [0.51498 , 0.10965 , 1.      ],\n",
       "       [0.53111 , 0.20906 , 1.      ],\n",
       "       [0.59793 , 0.095029, 1.      ],\n",
       "       [0.73848 , 0.086257, 1.      ],\n",
       "       [0.83065 , 0.18275 , 1.      ],\n",
       "       [0.8629  , 0.10965 , 1.      ],\n",
       "       [0.88364 , 0.27924 , 1.      ],\n",
       "       [0.93433 , 0.30848 , 1.      ],\n",
       "       [0.93433 , 0.19444 , 1.      ],\n",
       "       [0.92512 , 0.43421 , 1.      ],\n",
       "       [0.87903 , 0.43421 , 1.      ],\n",
       "       [0.87903 , 0.58626 , 1.      ],\n",
       "       [0.9182  , 0.71491 , 1.      ],\n",
       "       [0.85138 , 0.8348  , 1.      ],\n",
       "       [0.85599 , 0.94006 , 1.      ],\n",
       "       [0.70853 , 0.94298 , 1.      ],\n",
       "       [0.70853 , 0.87281 , 1.      ],\n",
       "       [0.59793 , 0.93129 , 1.      ],\n",
       "       [0.61175 , 0.83187 , 1.      ],\n",
       "       [0.78226 , 0.82895 , 1.      ],\n",
       "       [0.78917 , 0.8962  , 1.      ],\n",
       "       [0.90668 , 0.89912 , 1.      ],\n",
       "       [0.14862 , 0.92251 , 1.      ],\n",
       "       [0.15092 , 0.85819 , 1.      ],\n",
       "       [0.097926, 0.85819 , 1.      ],\n",
       "       [0.079493, 0.91374 , 1.      ],\n",
       "       [0.079493, 0.77632 , 1.      ],\n",
       "       [0.10945 , 0.79678 , 1.      ],\n",
       "       [0.12327 , 0.67982 , 1.      ],\n",
       "       [0.077189, 0.6886  , 1.      ],\n",
       "       [0.081797, 0.58626 , 1.      ],\n",
       "       [0.14862 , 0.58041 , 1.      ],\n",
       "       [0.14862 , 0.5307  , 1.      ],\n",
       "       [0.14171 , 0.41959 , 1.      ],\n",
       "       [0.08871 , 0.49269 , 1.      ],\n",
       "       [0.095622, 0.36696 , 1.      ],\n",
       "       [0.24539 , 0.3962  , 1.      ],\n",
       "       [0.1947  , 0.29678 , 1.      ],\n",
       "       [0.16935 , 0.22368 , 1.      ],\n",
       "       [0.15553 , 0.13596 , 1.      ],\n",
       "       [0.23848 , 0.12427 , 1.      ],\n",
       "       [0.33065 , 0.12427 , 1.      ],\n",
       "       [0.095622, 0.2617  , 1.      ],\n",
       "       [0.091014, 0.20322 , 1.      ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data[:,0:2]\n",
    "y=data[:,2]\n",
    "\n",
    "# use train_test_split to split your data\n",
    "# use a test size of 25% and a random state of 42\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate your DecisionTree Model\n",
    "model=DecisionTreeClassifier()\n",
    "# fit the model to the training data\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "# Make Predictions on the test set\n",
    "y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy and assign it to the variable acc on the test data.\n",
    "acc = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9583333333333334"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
